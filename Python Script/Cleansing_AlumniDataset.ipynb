{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleansing (Alumni Dataset)\n",
    "\n",
    "#### By : Vinayak Kumar Pathak"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries & Data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "alumni_data = pd.read_excel(r'F:\\\\CleansingAssessment\\\\Alumni_Dataset.xlsx', sheet_name = 'Data')\n",
    "sports_club = pd.read_excel(r'F:\\\\CleansingAssessment\\\\Alumni_Dataset.xlsx', sheet_name = 'Sports Club')\n",
    "course_structure = pd.read_excel(r'F:\\\\CleansingAssessment\\\\Alumni_Dataset.xlsx', sheet_name = 'Course Structure')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previewing & performing basic formatting on Main Data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alumni_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alumni_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "These columns are deleted for following reasons :\n",
    "Name Blank - It is supposed to indicate whether Name of an Alumni is blank or not but it has values for only one fourth of total data, hence it is not useful.\n",
    "Unnamed: 18 - It is an empty column with no values.\n",
    "Unnamed: 19 - It contains either 1 or 0 with no explanation.\n",
    "1 - It contains consecutive integers which is of no use.\n",
    "sadye.reynolds@beer.net : This column contains email addresses which doesn't even match with the corresponding value in 'Email Address' column.\n",
    "\n",
    "Apart from above mentioned reasons, no instructions were provided for these columns. Thus I assumed them to be insignificant.\n",
    "\"\"\"\n",
    "\n",
    "alumni_data = alumni_data.drop(['Name Blank', 'Unnamed: 18', 'Unnamed: 19', 1, 'sadye.reynolds@beer.net'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting data types to best possible match\n",
    "alumni_data = alumni_data.convert_dtypes()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Rows which are not following the required rules :"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Rule : The Name fields ('First Name' and 'Last Name') should not be blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a subset dataframe from alumni_data with rows having Null values for 'First Name' or 'Last Name' column.\n",
    "empty_names = alumni_data[(alumni_data['First Name'].isnull()) | (alumni_data['Last Name'].isnull())]\n",
    "\n",
    "# Checking if the dataframe has atleast one row\n",
    "if (empty_names.shape[0] > 0) :\n",
    "\n",
    "    # Adding a column in the subset dataframe\n",
    "    empty_names.loc[:,'Reason'] = \"Either First Name or Last Name is Blank\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Rule : All Email address should be unique, which means no more than one record should have same email address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a subset dataframe from alumni_data with rows having duplicate values for 'Email Address' column.\n",
    "dup_email = alumni_data.loc[alumni_data['Email Address'].duplicated(), :]\n",
    "\n",
    "if (dup_email.shape[0] > 0) :\n",
    "    dup_email.loc[:,'Reason'] = \"Contains duplicate Email\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Rule : All Email address should be valid which means it should be of the format abc@xyz.pqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular Expression for valid format of 'Email Address'\n",
    "pattern = re.compile('[a-zA-Z0-9._-]+@[a-zA-Z]+.[a-zA-Z]+')\n",
    "\n",
    "# Creating a subset dataframe from alumni_data with rows having email address of valid format.\n",
    "right_email = alumni_data[alumni_data['Email Address'].str.match(pattern, na=False)]\n",
    "\n",
    "# Creating a subset dataframe from alumni_data with rows not having email address of valid format.\n",
    "wrong_email = alumni_data.drop(right_email.index)\n",
    "\n",
    "if (wrong_email.shape[0] > 0) :\n",
    "    wrong_email.loc[:,'Reason'] = \"Wrong Format of Email Address\"\n",
    "\n",
    "# Setting \"right_email\" to None as it is no longer required\n",
    "right_email = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Rule : 'College Name' should not be blank if 'Degree' and 'Field of Study' is given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a subset dataframe from alumni_data where 'College Name' is blank when 'Degree' and 'Field of Study' is given\n",
    "blank_college_name = alumni_data[(alumni_data['College Name'].isnull()) & (alumni_data['Degree'].notnull()) & (alumni_data['Field of Study'].notnull())]\n",
    "\n",
    "if (blank_college_name.shape[0] > 0) :\n",
    "    blank_college_name.loc[:,'Reason'] = \"College Name is Empty even when Degree and Field of Study is given\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Rule : The sheet \"Course Structure\" is the table with the course details. The data in the columns 'College Name', 'Degree' & 'Field of Study' together should match with the one in the sheet \"Course Structure\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Merging (Left Join) \"alumni_data\" with \"course_structure\" on columns 'College Name', 'Degree' and 'Field of Study' and adding an indicator column 'Exists'.\n",
    "Indicator column tells if the row (subset on which both dataframes are merged) in \"alumni_data\" is present in \"course_structure\".\n",
    "If the value is 'both' then it exists, otherwise it does not.\n",
    "reset_index() method on \"alumni_data\" and set_index('index') method on the merged dataframe is used to make sure that the original index of the rows does not change .\n",
    "Since we performed left join, \"cn_d_fos\" contains all values from \"alumni_data\".\n",
    "\"\"\"\n",
    "cn_d_fos = pd.merge(alumni_data.reset_index(), course_structure, on=['College Name', 'Degree', 'Field of Study'], how='left', indicator='Exists').set_index('index')\n",
    "\n",
    "# Converting the values of 'Exists' column to boolean.\n",
    "cn_d_fos['Exists'] = np.where(cn_d_fos.Exists == 'both', True, False)\n",
    "\n",
    "# Creating a subset dataframe from \"cn_d_fos\" with rows having False value for 'Exists' column\n",
    "invalid_cn_d_fos = cn_d_fos[cn_d_fos['Exists'] == False]\n",
    "\n",
    "# Dropping the 'Exists' column since it is no longer required.\n",
    "invalid_cn_d_fos = invalid_cn_d_fos.drop(['Exists'], axis = 1)\n",
    "\n",
    "if (invalid_cn_d_fos.shape[0] > 0) :\n",
    "    invalid_cn_d_fos.loc[:,'Reason'] = \"College Name, Degree & Field of Study together does not match with the Course Structure sheet\"\n",
    "\n",
    "# Setting \"cn_d_fos\" to None as it is no longer required\n",
    "cn_d_fos = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Rule : 'Employer Name' cannot be blank if the 'Job Domain' or 'Job Title' are given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a subset dataframe from alumni_data where 'Employer Name' is blank when 'Job Domain' or 'Job Title' is given\n",
    "blank_employer_name = alumni_data[(alumni_data['Employer Name'].isnull()) & ((alumni_data['Job Domain'].notnull()) | (alumni_data['Job Title'].notnull()))]\n",
    "\n",
    "if (blank_employer_name.shape[0] > 0) :\n",
    "    blank_employer_name.loc[:,'Reason'] = \"Employer Name is Empty even when Job Domain or Job Title is given\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Rule : 'Date of Birth' should be of the format mm/dd/yyyy or mm-dd-yyyy and all three values must be given i.e., Day, Month and Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular Expression for valid format of 'Date of Birth'\n",
    "pattern2 = re.compile('[01]{0,1}[0-9](/|-)[0123]{0,1}[0-9](/|-)(19|20)[0-9]{2}')\n",
    "\n",
    "# Creating a subset dataframe from alumni_data with rows having date of birth of valid format.\n",
    "right_dob = alumni_data[alumni_data['Date of birth'].str.match(pattern2, na=False)]\n",
    "\n",
    "# Creating a subset dataframe from alumni_data with rows not having date of birth of valid format.\n",
    "wrong_dob = alumni_data.drop(right_dob.index)\n",
    "\n",
    "if (wrong_dob.shape[0] > 0) :\n",
    "    wrong_dob.loc[:,'Reason'] = \"Wrong Format of Date of Birth\"\n",
    "\n",
    "# Setting \"right_dob\" to None as it is no longer required\n",
    "right_dob = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Rule : 'Year of Graduation' and 'Year of Entry' has to be valid\n",
    "Bonus Rule : Year of Birth should be atleast before 2014 (Even if we assume a case similar to the prodigious case of Michael Kearney)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular Expression for Year\n",
    "pattern3 = re.compile('([12][09][0-9]{2})')\n",
    "\n",
    "# Changing data type of 'Date of birth' column to string.\n",
    "alumni_data['Date of birth'] = alumni_data['Date of birth'].astype(str)\n",
    "\n",
    "# Adding a 'YOB' (Year of Birth) column for ease of calculation\n",
    "alumni_data.loc[:,'YOB'] = alumni_data['Date of birth'].str.findall(pattern3)\n",
    "\n",
    "# Converting data type from list to string.\n",
    "alumni_data['YOB'] = [''.join(map(str, l)) for l in alumni_data['YOB']]\n",
    "\n",
    "# Replacing empty strings with N/A values\n",
    "alumni_data['YOB'] = alumni_data['YOB'].replace('', np.nan)\n",
    "\n",
    "# Converting data type from string to integer\n",
    "alumni_data['YOB'] = alumni_data['YOB'].astype('Int64')\n",
    "\n",
    "\"\"\"\n",
    "Following assumptions were made to check the validity of 'Year of Graduation' and 'Year of Entry' columns -\n",
    "1. 'Year of Entry' must be greater than Year of Birth\n",
    "2. 'Year of Graduation' must be greater than 'Year of Entry'\n",
    "3. 'Year of Graduation' must be lesser than the current year.\n",
    "\"\"\"\n",
    "# Creating a subset dataframe from alumni_data with rows not having valid values for 'Year of Graduation' and 'Year of Entry' columns\n",
    "invalid_year = alumni_data[(alumni_data['Year of Entry'] < alumni_data['YOB']) & (alumni_data['Year of Graduation'] < alumni_data['Year of Entry']) & (alumni_data['Year of Graduation'] > 2023)]\n",
    "\n",
    "# Creating a subset dataframe from alumni_data with rows having unrealistic values for Year of Birth\n",
    "invalid_yob = alumni_data[alumni_data['YOB'] > 2014]\n",
    "\n",
    "# Dropping the 'YOB' column since it is no longer required.\n",
    "alumni_data = alumni_data.drop(['YOB'], axis=1)\n",
    "invalid_year = invalid_year.drop(['YOB'], axis=1)\n",
    "invalid_yob = invalid_yob.drop(['YOB'], axis=1)\n",
    "\n",
    "if (invalid_year.shape[0] > 0) :\n",
    "    invalid_year.loc[:,'Reason'] = \"Year of Graduation or Year of Entry is not valid\"\n",
    "\n",
    "if (invalid_yob.shape[0] > 0) :\n",
    "    invalid_yob.loc[:,'Reason'] = \"Year of birth in Date of birth column has an unrealistic value\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Rule : Sheet \"Sports Club\" has a list of clubs in the school. The data in the sheet \"Assignment 1 - Data\" should have only the clubs listed in the sheet \"Sports Club\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a subset dataframe from alumni_data where values of 'Club1 ', 'CLub2', 'Club3' and 'Club4' columns matches with \"sports_club\" sheet\n",
    "valid_sports_club = alumni_data[(alumni_data['Club1 '].isin(sports_club['Sports Club'])) & (alumni_data['CLub2'].isin(sports_club['Sports Club'])) & (alumni_data['Club3'].isin(sports_club['Sports Club'])) & (alumni_data['Club4'].isin(sports_club['Sports Club']))]\n",
    "\n",
    "# Creating a subset dataframe from alumni_data where values of 'Club1 ', 'CLub2', 'Club3' and 'Club4' columns doesn't matches with \"sports_club\" sheet\n",
    "invalid_sports_club = alumni_data.drop(valid_sports_club.index)\n",
    "\n",
    "if (invalid_sports_club.shape[0] > 0) :\n",
    "    invalid_sports_club.loc[:,'Reason'] = \"Name of the Club is not listed in Sports Club sheet\"\n",
    "\n",
    "# Setting \"valid_sports_club\" to None as it is no longer required\n",
    "valid_sports_club = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Rule : Cells with value N/A are not allowed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a subset dataframe from alumni_data with rows not having N/A values\n",
    "no_na_val = alumni_data.dropna()\n",
    "\n",
    "# Creating a subset dataframe from alumni_data with rows having N/A values\n",
    "na_val = alumni_data.drop(no_na_val.index)\n",
    "\n",
    "if (na_val.shape[0] > 0) :\n",
    "    na_val.loc[:,'Reason'] = \"Cell(s) contains N/A value\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating dropped rows in a single DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset_index() method is used to preserve the original index of rows for easy reference in original file.\n",
    "dropped_rows = pd.concat([empty_names, dup_email, wrong_email, blank_college_name, invalid_cn_d_fos, blank_employer_name, wrong_dob, invalid_year, invalid_yob, invalid_sports_club, na_val], axis = 0).reset_index()\n",
    "dropped_rows = dropped_rows.sort_values(by=['index'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving DataFrame into CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_rows.to_csv(r'F:\\\\CleansingAssessment\\\\DroppedRows_AlumniDataset.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
